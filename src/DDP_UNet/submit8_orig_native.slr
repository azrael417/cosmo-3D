#!/bin/bash -l
#SBATCH --nodes=1
#SBATCH --time=04:00:00
#SBATCH -C gpu 
#SBATCH --account m1759
#SBATCH --gres=gpu:8
#SBATCH --exclusive
#SBATCH -c 80

module unload cuda
module load pytorch/v1.4.0-gpu
module list
export HDF5_USE_FILE_LOCKING=FALSE

#nodes=$(scontrol show hostnames $SLURM_JOB_NODELIST) # Getting the node names
#nodes_array=( $nodes )
#worker_num=$(($SLURM_JOB_NUM_NODES - 1))

#master_node=${nodes_array[0]}

#for ((  i=0; i<=$worker_num; i++ ))
#do
#  node_i=${nodes_array[$i]}
#  srun --nodes=1 --ntasks=1 -w $node_i python -m torch.distributed.launch --nproc_per_node=8 --nnodes=8 --node_rank=$i --master_addr=$master_node train.py --run_num=13# &
#  pids[${i}]=$!
#  echo "Training started on node $i"
#done

rankspernode=8
srun -u -N ${SLURM_NNODES} -n $(( ${SLURM_NNODES} * ${rankspernode} ))  -c $(( 80 / ${rankspernode} )) --cpu_bind=cores \
     python train.py --yaml_config config/UNet_native.yaml --run_num=13

## Wait for completion
#for pid in ${pids[*]}; do
#    wait $pid
#done

date

