2020-06-22 23:28:22,267 - root - INFO - rank 1, begin data loader init (local rank 1)
2020-06-22 23:28:22,267 - root - INFO - ------------------ Configuration ------------------
2020-06-22 23:28:22,267 - root - INFO - Configuration file: /opt/DDP_UNet/config/UNet_transpose.yaml
2020-06-22 23:28:22,267 - root - INFO - Configuration name: default
2020-06-22 23:28:22,272 - root - INFO - weight_init ordereddict([('conv_init', 'normal'), ('conv_scale', 0.02), ('conv_bias', 0.0)])
2020-06-22 23:28:22,272 - root - INFO - lr 0.0001
2020-06-22 23:28:22,272 - root - INFO - data_path /data/DDP_trdat_tra.h5
2020-06-22 23:28:22,272 - root - INFO - transposed_input 1
2020-06-22 23:28:22,272 - root - INFO - rotate_input 1
2020-06-22 23:28:22,272 - root - INFO - ngpu 1
2020-06-22 23:28:22,272 - root - INFO - Nsamples 20
2020-06-22 23:28:22,272 - root - INFO - num_epochs 5
2020-06-22 23:28:22,272 - root - INFO - num_data_workers 2
2020-06-22 23:28:22,272 - root - INFO - LAMBDA_2 0.01
2020-06-22 23:28:22,273 - root - INFO - data_size 256
2020-06-22 23:28:22,273 - root - INFO - N_out_channels 5
2020-06-22 23:28:22,273 - root - INFO - batch_size 1
2020-06-22 23:28:22,273 - root - INFO - cpu_pipeline 0
2020-06-22 23:28:22,273 - root - INFO - ---------------------------------------------------
2020-06-22 23:28:22,273 - root - INFO - rank 0, begin data loader init (local rank 0)
Transposed Input
Transposed Input
Enable Rotation
Use GPU Pipeline
Enable Rotation
Use GPU Pipeline
/opt/python/cp37-cp37m/lib/python3.7/site-packages/nvidia/dali/plugin/base_iterator.py:124: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
2020-06-22 23:28:45,172 - root - INFO - rank 0, data loader initialized
/opt/python/cp37-cp37m/lib/python3.7/site-packages/nvidia/dali/plugin/base_iterator.py:124: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
2020-06-22 23:28:45,194 - root - INFO - rank 1, data loader initialized
2020-06-22 23:28:46,657 - root - INFO - DistributedDataParallel(
  (module): UNet(
    (conv_down1): Sequential(
      (0): Conv3d(4, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv_down2): Sequential(
      (0): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv_down3): Sequential(
      (0): Conv3d(128, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv_down4): Sequential(
      (0): Conv3d(256, 512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv_down5): Sequential(
      (0): Conv3d(512, 512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv_down6): Sequential(
      (0): Conv3d(512, 512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (conv_up6): Sequential(
      (0): ConvTranspose3d(512, 512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): ReLU(inplace=True)
    )
    (conv_up5): Sequential(
      (0): ConvTranspose3d(1024, 512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): ReLU(inplace=True)
    )
    (conv_up4): Sequential(
      (0): ConvTranspose3d(1024, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): ReLU(inplace=True)
    )
    (conv_up3): Sequential(
      (0): ConvTranspose3d(512, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): ReLU(inplace=True)
    )
    (conv_up2): Sequential(
      (0): ConvTranspose3d(256, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
      (1): ReLU(inplace=True)
    )
    (conv_last): ConvTranspose3d(128, 5, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))
    (tanh): Tanh()
  )
)
2020-06-22 23:28:46,658 - root - INFO - Starting Training Loop...
2020-06-22 23:29:15,538 - root - INFO - Time taken for epoch 1 is 28.87941837310791 sec
2020-06-22 23:29:15,538 - root - INFO - total time / step = 1.4439649820327758, fw time / step = 0.07168748378753662, bw time / step = 1.1193713426589966, exposed io time / step = 0.25290615558624263, iters/s = 0.6925375701232217, logging time = 0.0
2020-06-22 23:29:43,474 - root - INFO - Time taken for epoch 2 is 27.905149698257446 sec
2020-06-22 23:29:43,474 - root - INFO - total time / step = 1.3952499628067017, fw time / step = 0.00667496919631958, bw time / step = 1.1228719353675842, exposed io time / step = 0.26570305824279794, iters/s = 0.7167174532571841, logging time = 0.0
2020-06-22 23:30:11,482 - root - INFO - Time taken for epoch 3 is 27.95311427116394 sec
2020-06-22 23:30:11,482 - root - INFO - total time / step = 1.3976480484008789, fw time / step = 0.004632723331451416, bw time / step = 1.1255577445030212, exposed io time / step = 0.26745758056640634, iters/s = 0.7154877089007863, logging time = 0.0
2020-06-22 23:30:39,528 - root - INFO - Time taken for epoch 4 is 27.967395305633545 sec
2020-06-22 23:30:39,528 - root - INFO - total time / step = 1.3983620285987854, fw time / step = 0.004601669311523437, bw time / step = 1.1272005438804626, exposed io time / step = 0.2665598154067994, iters/s = 0.715122392877072, logging time = 0.0
2020-06-22 23:31:07,599 - root - INFO - Time taken for epoch 5 is 28.0170795917511 sec
2020-06-22 23:31:07,599 - root - INFO - total time / step = 1.400846529006958, fw time / step = 0.004633653163909912, bw time / step = 1.129230260848999, exposed io time / step = 0.2669826149940491, iters/s = 0.7138540727290712, logging time = 0.0
2020-06-22 23:31:07,940 - root - INFO - DONE ---- rank 1
2020-06-22 23:31:07,957 - root - INFO - DONE ---- rank 0
